{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnH94wo6Lkbc"
   },
   "source": [
    "# 라이브러리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sTXqWPzdHQF3"
   },
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ni9uNdvhd3nd",
    "outputId": "49386b16-c0a2-41f0-960d-b6b67929f745"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lih2d8pjLzom"
   },
   "source": [
    "# 파일경로\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XIyn3b34Lm96"
   },
   "outputs": [],
   "source": [
    "# 1. CSV 파일 불러오기\n",
    "file_path = \"/content/drive/MyDrive/소프개인/new.csv\"  # Colab 경로 또는 적절한 파일 경로로 변경\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2hM1V3xwMJJF"
   },
   "source": [
    "# 데이터 전처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5b9_yEZpMLfT"
   },
   "outputs": [],
   "source": [
    "timesteps = 6  # 예: 3초의 영상에서 0.5초 간격으로 추출된 경우\n",
    "feature_size = data.shape[1] - 1  # Label 열을 제외한 나머지 데이터\n",
    "\n",
    "# 입력 데이터와 라벨 분리\n",
    "X = data.iloc[:, :-1].values  # 마지막 열인 'Label'을 제외한 나머지 데이터\n",
    "y = data['Label'].values\n",
    "\n",
    "# 라벨 인코딩 (문자열 라벨을 정수로 변환)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o2dkUCHoUjc_",
    "outputId": "a489c0da-ebc5-4f7b-c62b-6a00867ef459"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_seq shape: (7536, 6, 111)\n",
      "y_seq shape: (7536,)\n"
     ]
    }
   ],
   "source": [
    "X_seq = []\n",
    "y_seq = []\n",
    "\n",
    "# timesteps 길이만큼 데이터를 묶어서 시퀀스 생성\n",
    "for i in range(len(X) - timesteps):\n",
    "    X_seq.append(X[i:i+timesteps])  # X의 timesteps 묶음 추가\n",
    "    y_seq.append(y[i + timesteps])  # 각 시퀀스 다음의 y 값을 라벨로 추가\n",
    "\n",
    "# 리스트를 배열로 변환\n",
    "X_seq = np.array(X_seq)\n",
    "y_seq = np.array(y_seq)\n",
    "\n",
    "# 최종 데이터 크기 확인\n",
    "print(\"X_seq shape:\", X_seq.shape)  # 예상 출력: (samples, timesteps, features)\n",
    "print(\"y_seq shape:\", y_seq.shape)  # 예상 출력: (samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J86vhNqPMjLo",
    "outputId": "82a177cd-233f-4d9f-aee5-944882fbe1c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    }
   ],
   "source": [
    "print(feature_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwJzRujuSDNb"
   },
   "source": [
    "# 학습데이터 분할\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IAQyWnFkSEg-"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.25, random_state=42, stratify=y_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6j35yqJSQP6"
   },
   "source": [
    "# 파이토치 텐서변환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvmRfHHVSJtf"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 5. PyTorch Tensor로 변환 (NaN을 -1로 대체)\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# NaN 값을 -1로 대체\n",
    "X_train = torch.nan_to_num(X_train, nan=-1.0)\n",
    "X_test = torch.nan_to_num(X_test, nan=-1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M79H9PBdVk_F",
    "outputId": "b751586d-62ad-4038-b5d5-60278d60076e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN in X_train: tensor(0)\n",
      "Inf in X_train: tensor(0)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 검증\n",
    "print(\"NaN in X_train:\", np.isnan(X_train).sum())\n",
    "print(\"Inf in X_train:\", np.isinf(X_train).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1Pgnzr5STtj"
   },
   "source": [
    "# 모델정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z73ol_FyOLxF"
   },
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # LSTM에 입력\n",
    "        h_0 = torch.zeros(num_layers, x.size(0), hidden_size).to(x.device)\n",
    "        c_0 = torch.zeros(num_layers, x.size(0), hidden_size).to(x.device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h_0, c_0))  # LSTM의 출력\n",
    "        out = out[:, -1, :]  # 마지막 time step의 출력 사용\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "input_size = feature_size\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "num_classes = len(np.unique(y))\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, num_classes)\n",
    "\n",
    "\"\"\"# 손실함수와 최적화\"\"\"\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xjBYiGDNSUtn",
    "outputId": "03257f51-0be6-40d9-d8a8-e161f5d5ddd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/150], Loss: 2.9502\n",
      "Epoch [20/150], Loss: 2.6972\n",
      "Epoch [30/150], Loss: 2.2660\n",
      "Epoch [40/150], Loss: 1.8117\n",
      "Epoch [50/150], Loss: 1.4599\n",
      "Epoch [60/150], Loss: 1.1850\n",
      "Epoch [70/150], Loss: 0.9624\n",
      "Epoch [80/150], Loss: 0.7835\n",
      "Epoch [90/150], Loss: 0.6450\n",
      "Epoch [100/150], Loss: 0.5317\n",
      "Epoch [110/150], Loss: 0.4403\n",
      "Epoch [120/150], Loss: 0.3684\n",
      "Epoch [130/150], Loss: 0.3108\n",
      "Epoch [140/150], Loss: 0.2638\n",
      "Epoch [150/150], Loss: 0.2264\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "epochs = 150\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 옵티마이저 초기화 (에포크 밖에서)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 손실 함수 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # 모델을 학습 모드로 설정\n",
    "\n",
    "    optimizer.zero_grad()  # 기울기 초기\n",
    "\n",
    "    # 순전파\n",
    "    outputs = model(X_train)  # Pass input data through the model\n",
    "    loss = criterion(outputs, y_train)  # Compute loss\n",
    "\n",
    "    # 역전파\n",
    "    loss.backward()  # 기울기 계산\n",
    "    optimizer.step()  # 파라미터 업데이트\n",
    "\n",
    "    # 에포크마다 손실 출력\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Uj4G8k7SWd8"
   },
   "source": [
    "# 손실함수와 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9E1ilFHSZTd"
   },
   "source": [
    "# 모델학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urZDr3czSfQ_"
   },
   "source": [
    "# 모델평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HPgHkk3GSeZF",
    "outputId": "f1e39b73-af18-4fd6-a449-f4c304c89a9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.34%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    accuracy = (predicted == y_test).sum().item() / y_test.size(0)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ptMyq56EmQjQ"
   },
   "outputs": [],
   "source": [
    "# 모델 전체 저장\n",
    "torch.save(model, '/90_newcsv.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fzd4HP06Z2kP",
    "outputId": "29fbaf81-e86a-4f42-f660-afad8f53e930"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-596f56c34bcc>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test, y_test = torch.tensor(X_test), torch.tensor(y_test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        88\n",
      "           1       0.96      0.98      0.97        90\n",
      "           2       0.85      0.74      0.79        90\n",
      "           3       0.81      0.84      0.83        88\n",
      "           4       0.84      0.88      0.86        88\n",
      "           5       0.99      0.96      0.97        72\n",
      "           6       0.91      0.90      0.90        88\n",
      "           7       0.85      0.89      0.87        89\n",
      "           8       0.87      0.97      0.91        87\n",
      "           9       0.95      0.89      0.92        90\n",
      "          10       0.97      0.97      0.97        72\n",
      "          11       0.92      0.89      0.90        88\n",
      "          12       0.81      0.81      0.81        89\n",
      "          13       0.90      0.84      0.87        89\n",
      "          14       0.98      0.92      0.95        90\n",
      "          15       0.73      0.75      0.74        89\n",
      "          16       0.97      1.00      0.99        72\n",
      "          17       0.93      0.93      0.93        88\n",
      "          18       0.93      0.92      0.92        87\n",
      "          19       1.00      1.00      1.00        72\n",
      "          20       0.91      0.88      0.89        88\n",
      "          21       0.97      1.00      0.98        90\n",
      "\n",
      "    accuracy                           0.90      1884\n",
      "   macro avg       0.91      0.91      0.91      1884\n",
      "weighted avg       0.90      0.90      0.90      1884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 테스트 데이터셋 로드 (예시로 Tensor 사용)\n",
    "# X_test와 y_test는 테스트 데이터와 라벨을 텐서로 준비한 것입니다\n",
    "X_test, y_test = torch.tensor(X_test), torch.tensor(y_test)\n",
    "\n",
    "# 모델을 평가하는 함수 정의\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    # classification report 출력\n",
    "    report = classification_report(y_test.numpy(), preds.numpy())\n",
    "    print(report)\n",
    "\n",
    "# 사용 예시\n",
    "evaluate_model(model, X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
